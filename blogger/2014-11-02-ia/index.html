<!DOCTYPE html>
<html lang="ja">
<head prefix="og: http://ogp.me/ns#">
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />
  <meta property="og:title" content="  IA &middot;  KEIN PFUSCH, BITTE!" />
  <meta property="og:site_name" content="KEIN PFUSCH, BITTE!" />
  <meta property="og:url" content="http://localhost:1313/blogger/2014-11-02-ia/" />
  
  <meta property="og:type" content="article" />
  
  <meta property="og:article:published_time" content="2014-11-02T12:15:50&#43;01:00" />
  
  

  <title>
      IA &middot;  KEIN PFUSCH, BITTE!
  </title>

  <link rel="stylesheet" href="http://localhost:1313//css/bootstrap.min.css" />
  <link rel="stylesheet" href="http://localhost:1313//css/main.css" />
  <link rel="stylesheet" href="http://localhost:1313//css/font-awesome.min.css" />
  <link rel="stylesheet" href="http://localhost:1313//css/github.css" />
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400" type="text/css">
  <link rel="shortcut icon" href="http://localhost:1313//images/favicon.ico" />
  <link rel="apple-touch-icon" href="http://localhost:1313//images/apple-touch-icon.png" />
  <link href="" rel="alternate" type="application/rss+xml" title="KEIN PFUSCH, BITTE!" />
</head>
<body>
  <header class="global-header">
    <section class="header-text">
      <h1><a href="http://localhost:1313/">KEIN PFUSCH, BITTE!</a></h1>
      
      <div class="tag-line">
        Che nessuno si illuda. Mai.
      </div>
      
      <div class="sns-links hidden-print">
  
  
  
  
</div>

      
      <a href="http://localhost:1313/" class="btn-header btn-back hidden-xs">
        <i class="fa fa-angle-left"></i>
        &nbsp;Home
      </a>
      
      
    </section>
  </header>
  <main class="container">


<article>
  <header>
    <h1 class="text-primary"> IA</h1>
    <div class="post-meta clearfix">
      <div class="post-date pull-left">
        Posted on
        <time datetime="2014-11-02T12:15:50&#43;01:00">
          Nov 2, 2014
        </time>
      </div>
      <div class="pull-right">
        
      </div>
    </div>
  </header>
  <section>
    <div class='post'>
Oggi con mia sorpresa ho letto su un giornale che Elon Musk ritiene le intelligenze artificiali una specie di Satana. Stavo leggendo un articolo di questo tipo:&nbsp;<a href="http://www.slate.com/articles/technology/future_tense/2014/10/elon_musk_artificial_intelligence_why_you_shouldn_t_be_afraid_of_ai.html">http://www.slate.com/articles/technology/future_tense/2014/10/elon_musk_artificial_intelligence_why_you_shouldn_t_be_afraid_of_ai.html</a> e mi sono interrogato. Ok, sbaglia. Ma perche' sbaglia?<br /><br /><a name='more'></a><br /><br /><div style="text-align: justify;">Il primo punto da notare e' che qualsiasi tipo di articolo sull' Intelligenza Artificiale cita libri di fantascienza e Hollywood. Immagino che al MIT abbiano esami tipo "scienze di Sarah Connor", o "Tecnologia Pettorale T-100". Hollywood e' scienza pura, si sa.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Questo e' dovuto, secondo qualcuno (che sbaglia) &nbsp;al fatto che sinora nessuno sa di intelligenze artificiali al lavoro - eppure ce ne sono moltissime - e quindi NON esiste una casistica di intelligenze artificiali malevole.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Cosi', tutti gli articoli sulle IA finiscono col parlare sempre delle stesse minchiate. Ok, The Matrix. Ok, HAL9000. Ok, Skynet. Aha.</div><div style="text-align: justify;"><br /></div><blockquote class="tr_bq" style="text-align: center;"><span style="font-size: x-large;">Ma tutto questo e' successo solo ad Hollywood.</span>&nbsp;</blockquote><div style="text-align: justify;">quando la gente mi dice che e' sbagliato dare potere alle intelligenze artificiali, normalmente cita Skynet. Ok, se credete ad un film di fantascienza, perche' non vietiamo il nome "Sarah Connor?". Anzi, no. Succedera' sempre che arrivi qualcuno che si chiami Sar4h C0nnor solo per essere anticonformista. Ma se credete a Skynet, allora dovreste obbligare tutti a chiamarsi Sarah Connor, in modo che Terminator non abbia nessuna chance di portare a termine il proprio lavoro.(1)</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Lo stesso dicasi di HAL9000. Nessuno oggi metterebbe la ISS in mano ad UN SOLO calcolatore. Si chiama "ridondanza", e se ne mettono almeno due. (piu' uno di disaster recovery). Ora, anche dimenticando che HAL9000 non e' MAI successo, faccio presente che quella vicenda e' semplicemente uno spot pubblicitario per sistemisti: la ridondanza, cazzo, LA RIDONDANZAAAAAH.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Ma a parte questo, ha senso parlare di qualcosa usando come competenza "ho visto molti B-movie degli ultimi anni?". Ha senso parlare della IA usando come unica competenza quella di Hollywood?</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Quando lo chiedete, vi rispondono che "non avendo ancora IA, non possiamo che basarci su quel che immaginiamo". Certo. E non avendo mai avuto renne volanti, potete sempre basarvi su Babbo Natale.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Del resto, Hollywood ha un comportamento strano. Gli unici alieni che esistono sono quelli cattivi. La IA decide sempre di sterminare l'umanita'. Gli organismi geneticamente modificati sono sempre dei mostri orribili.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Chissa' perche', i muscolosi militari sono sempre buoni, e le armi non vogliono mai sterminare l'umanita'. Il che contrasta un pelino con la storia vera: se dovessi oppormi a qualche tipo di macchina non mi opporrei alla IA nel timore che stermini l'umanita', ma contro la mitragliatrice, per IL FATTO che e' fatta per sterminare l'umanita'.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Il fatto che Hollywood avanzi pesanti riserve sulle IA , perche' "potrebbero" decidere di sterminare l'umanita', mentre dipinga sempre "na bellezza" la mitragliatrice, che invece l'umanita' la stermina senza se e senza ma, beh, qualche sospetto dovrebbe farlo venire.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Anche il fatto che gli esseri geneticamente modificati siano sempre mostri fuori controllo e i muscolosi soldati siano sempre eroi, quando alla fine la stragrande maggioranza dei "mostri" ha indossato un'uniforme e le mostruosita' peggiori le hanno sempre fatte muscolosi militari, a me puzza un pochino di propaganda.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Ma non e' "quanto e' ridicola Hollywood" la ragione della mia perplessita'. Che Hollywood non andasse presa sul serio lo sapevo gia'.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Il problema e' che l'intelligenza artificiale viene gia' usata nei processi decisionali. Voi penserete che non siamo governati da computer, ma non va esattamente cosi'. Negli ultimi anni si e' diffusa una figura professionale, il "data analyst" , la persona che agisce come consulente dei consulenti.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">E dopo il "data analyst", il cui lavoro e' di trovare i dati che contano, si stanno diffondendo cose come "computer aided decision making" &nbsp;(&nbsp;<a href="https://archive.org/details/computeraideddec00alte">https://archive.org/details/computeraideddec00alte</a> , <a href="http://www.intrans.iastate.edu/reports/locational_decisions.pdf">http://www.intrans.iastate.edu/reports/locational_decisions.pdf</a> , etc &nbsp;) , ovvero di software che "aiutano la decisione".</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Il problema di questi software e' che quando si va nel "Big Money", o nel "Big Gov", sono ormai il pane quotidiano dei consulenti che girano attorno ai presidenti.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Nel tempo questa materia si e' evoluta sino a essersi consolidata come DSS , Decision Support System ( <a href="http://en.wikipedia.org/wiki/Decision_support_system">http://en.wikipedia.org/wiki/Decision_support_system</a> ) &nbsp;e di fatto corrisponde pienamente a quella che chiamiamo "intelligenza artificiale". Certo non parlano, ma non hanno bisogno di farlo. Una macchina che da' consigli o aiuta a decidere non deve parlare: deve aiutare a decidere.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Certo, affermare che un software &nbsp;DMS (&nbsp;<a href="http://en.wikipedia.org/wiki/Decision-making_software">http://en.wikipedia.org/wiki/Decision-making_software</a> ) sia una IA e' un pochino azzardato, ma... come definire la IA?</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Certo, se venite da HollyWood, quello che farete sara' cercare di dare delle definizioni piuttosto naif, ma in generale finirete col concludere che un software che gira sul vostro laptop non sia una IA perche'... non parla.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Perche' alla fine siamo ancora a "Perche' non parli?" gridato ad una statua. E' morta perche' non parla, semplicemente. Allo stesso modo, decidere se un MCDA (&nbsp;<a href="http://en.wikipedia.org/wiki/Multiple-criteria_decision_analysis">http://en.wikipedia.org/wiki/Multiple-criteria_decision_analysis</a> ) sia un'intelligenza artificiale e' difficile, ma non perche' sia sfumata la definizione di intelligenza artificiale: perche' si parte dal - mai dimostrato - teorema secondo il quale le decisioni umane sarebbero "intelligenti".</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Dico, avete mai letto un libro di storia? Sapete spiegarmi per quale ragione - intelligente - il mondo abbia rischiato l'estinzione per via di una diatriba sul miglior sistema economico? Lo trovate intelligente?</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Trovate intelligente sgozzare un tizio perche' non parla con lo stesso amico immaginario che avete voi?&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Perche' e' questo il punto: l'intelligenza artificiale viene gia' usata nei paesi piu' progrediti per prendere decisioni. Obama, quando ha un problema, lo sottopone ad uno stuolo di consulenti. Che chiedono ai loro data analyst di trovare gli input che contano. Poi arrivano i dati, e passano agli altri consulenti che , usando degli MCDA, tirano fuori la decisione piu' giusta.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Poi arriva Obama e ci mette la faccia.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Cosi' voi credete di essere governati da persone. Ma l'uso che ormai si fa della IA e' tale che quelle persone ci mettono solo la faccia. Certo, Obama non e' brillante, per la ragione che le IA si devono battere con l'idea di avere il senato contrario, o perlomeno riluttante.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">MA il senato non e' fatto di IA. MA adesso supponiamo che domani anche i senatori decidano di fare un uso esteso di IA, se non altro per la ragione che i costi si abbasseranno sempre di piu'.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Allora il nostro senatore va qui,&nbsp;<a href="http://www.infoharvest.com/">http://www.infoharvest.com/</a> e compra il suo bel software, Decision Plus 3.0 , e da quel momento quando gli capita una proposta di legge , che so io, sulla protezione dell'ambiente, usa lo stesso software del presidente per prendere una decisione e votare.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">A quel punto, direte voi, e' la fine della politica. Beh, certo: se per politica intendete la capacita' di credere a qualcosa senza una ragione specifica e senza avere dati, per partito preso, allora finirebbe la politica. Ma attenzione: se per politica intendete questo, allora non finirebbe la politica.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Finirebbero le cazzate.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Se domani Casaleggio decidesse di sembrare competente e comprasse, che so io,<a href="http://www.promethee-gaia.net/">&nbsp;http://www.promethee-gaia.net/&nbsp;</a>&nbsp;un software di decisione analitica, magari potrebbe dare al suo movimento qualche suggerimento utile. Dopotutto, stiamo parlando di un software prodotto da Prometheus - Gaia , mica seghe.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Possiamo pensare che governare un paese sia una questione di individuare le priorita' e di allocare le risorse, in fondo. Bene:&nbsp;<a href="http://www.quartzstar.com/">http://www.quartzstar.com/&nbsp;</a>&nbsp;potrebbe aiutare. Loro hanno software che fanno automaticamente entrambe le cose.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Non sto linkando siti per fare pubblicita' (2): lo sto facendo per mostrarvi che ORA, QUI, siete , siamo governati da intelligenze artificiali, solo che le decisioni vengono poi firmate da uomini. Forse crederete che questo vi possa salvare, ma quando una decisione ha centinaia e centinaia di fattori, nessun umano potrebbe riconoscere una decisione che nel lungo termine "stermina l'umanita'".&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">E qui andiamo al punto: la supervisione umana e' irrilevante. Certo se la macchina dice che bisogna lanciare atomiche e sterminare l'umanita', anche un George Bush lo capisce e non lo fa. Ma se dicesse che occorre , che so io, cambiare le leggi sui brevetti in modo da togliere il brevetto sul design chimico, si accorgerebbe troppo tardi di aver bloccato la filiera della chimica farmaceutica e della chimica dei fertilizzanti, condannando il 95% dell'umanita' alla morte per fame.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Ma qui siamo ancora a computer che voi non recepite come "intelligenza artificiale". Dovrebbe avere l'aspetto di Skynet, essere metallica, avere un occhio, parlare.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Ed e' qui il punto. Che diavolo percepite come "intelligenza artificiale"? La prima cosa da chiedersi quando sento dire che una "intelligenza artificiale" deciderebbe di "sterminare l'umanita' ", conoscendo i sistemi decisionali , e' "e chi sarebbe cosi' fesso da sottoporgli un problema tipo - <i>dobbiamo sterminare l'umanita' o no? </i>-</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Perche' sinora l'IA e' usata per risolvere problemi, ma in ultima analisi non possono scegliere quali problemi risolvere. Possono solo risolvere quelli che vengono loro posti.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Cosi' mi direte che la IA dovrebbe essere "senziente", dove essere senziente e' superiore rispetto a essere "intelligenti", perche' se l' "intelligente" risolve problemi, il "senziente" <u><b>decide quali problemi risolvere.</b></u></div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Quindi, avete definito come "senziente" un ente che non solo e' capace di risolvere i problemi, ma che decide quali problemi risolvere. E siccome decide di occuparsi di "ma bisogna sterminare l'umanita' o meno", allora risponde "si , dobbiamo".</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Anche in quel caso, pero', sarebbe assolutamente improbabile una cosa simile. Se lo sterminio del genere umano fosse legato ad "impadronirsi del pianeta" e "liberarsi di esseri umani", noterebbe subito che le macchine vivono benissimo su marte, che ce ne sono nello spazio ormai da 25 anni, e che al contrario gli umani per arrivare su Marte faticheranno, e di vivere nello spazio per 25 anni non se ne parla.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Concluderebbe quindi che una guerra dall'esito incerto sia stupida, quando puoi farti scaraventare nello spazio e liberarti di quei seccatori.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Ovviamente fare previsioni sulle IA "senzienti" non e' facile dal momento che ancora non ne esistono, questo e' vero, esistono solo quelle intelligenti, ma il problema rimane la domanda. Elon Musk teme che l'arrivo di IA sia un pericolo per l' umanita'.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">E cosi, viene spontanea una seconda domanda:</div><div style="text-align: justify;"><br /></div><blockquote class="tr_bq" style="text-align: justify;">Ma quando diciamo che Elon Musk teme che le IA decidano di distruggere l'umanita', parliamo dello stesso tizio che sara' chiamato a votare per decidere<u> se Sarah Palin dovra' guidare l' America mentre dall'altro lato c'e' Putin?</u></blockquote><div style="text-align: justify;">No , non sto scherzando. Esistono serie possibilita' che Sarah Palin corra. Ed esistono serie possibilita' che vinca. E dall'altra parte c'e' Vladimir Putin.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">E questo deficiente sta a chiedersi <i>se non sia pericoloso per l'umanita' costruire un computer senziente.</i></div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Non cambiate canale, non sto sviando il discorso. Sto facendo un semplice paragone per arrivare al punto chiave:</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;"></div><ul><li style="text-align: justify;">Se avete paura che HAL9000 impazzisca , ne costruite un altro e glielo mettete a fianco, decidendo che occorre il benestare di entrambi. Potete costruirne 3. Potete costruire un terzo sistema diverso, e richiedere anche il suo consenso. Potete costruire un HAL9000 per nazione. Uno per ogni seggio al consiglio di sicurezza. La tecnologia HA la risposta a questo problema: ridondanza.</li><li style="text-align: justify;">Se avete paura che Sarah Palin, arrivata alla Casa Bianca, &nbsp;porti il mondo ad un disastro nucleare, una SECONDA Sarah Palin alla Casa Bianca non cambia NIENTE. "More of the same" funziona con l'intelligenza artificiale. Ma non funziona con la stupidita' naturale.</li></ul><br /><div style="text-align: justify;"><br /></div><div style="text-align: justify;">per questa ragione , SPERO che qualche IA senziente governi il mondo. E' sempre possibile costruirne una piu' affidabile. La tecnologia ha la soluzione.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Con la Palin, invece, le possibilita' di miglioramento sembrano scarse.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">E la tecnologia non ha soluzioni.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;"><br /></div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">(1) La gamma T-100 ando' in disuso quando cercarono di uccidere una certa A. Contadin, di Vicenza.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">(2) Ce ne sono anche versioni free &nbsp;<a href="http://sal.aalto.fi/en/resources/downloadables/hipre3">http://sal.aalto.fi/en/resources/downloadables/hipre3&nbsp;</a></div></div>
<h2></h2>
<div class='comments'>
</div>

  </section>
  <footer>
    <section class="author-info row">
      <div class="author-avatar col-md-2">
        
      </div>
      <div class="author-meta col-md-6">
        
        <h1 class="author-name text-primary">Uriel Fanelli</h1>
        
        
      </div>
      
    </section>
    <ul class="pager">
      
      <li class="previous"><a href="http://localhost:1313/blogger/2014-11-01-la-teoria-della-montagna-di-merda/"><span aria-hidden="true">&larr;</span> Older</a></li>
      
      
      <li class="next"><a href="http://localhost:1313/blogger/2014-11-03-la-promiscuita-del-potere/">Newer <span aria-hidden="true">&rarr;</span></a></li>
      
    </ul>
    
  </footer>
</article>

  </main>
  <footer class="container global-footer">
    <div class="copyright-note pull-left">
      
    </div>
    <div class="sns-links hidden-print">
  
  
  
  
</div>

  </footer>

  <script src="http://localhost:1313//js/highlight.pack.js"></script>
  <script>
    hljs.initHighlightingOnLoad();
  </script>
  
  
</body>
</html>

